apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: rook-ceph-cluster
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  destination:
    server: https://kubernetes.default.svc
    namespace: rook-ceph
  project: default
  source:
    chart: rook-ceph-cluster
    repoURL: https://charts.rook.io/release
    targetRevision: v1.15.2
    helm:
      valuesObject:
        configOverride: |
          [global]
          mon_osd_down_out_interval = 1800

        # doesnt work:

        # cephClusterSpec:
        #   cephVersion:
        #     image: quay.io/ceph/ceph:v18.2.2

        # cephVersion:
        #   image: quay.io/ceph/ceph:v18.2.2

        ingress:
          dashboard:
            ingressClassName: nginx
            annotations:
              external-dns.alpha.kubernetes.io/target: ingress.ceph.impl.nl
              external-dns.alpha.kubernetes.io/cloudflare-proxied: "false"
              cert-manager.io/cluster-issuer: letsencrypt-production
            host:
              name: rook.ceph.impl.nl
            tls:
              - secretName: rook.ceph.impl.nl
                hosts:
                  - rook.ceph.impl.nl
        monitoring:
          enabled: true

        toolbox:
          enabled: true

        cephClusterSpec:

          cephVersion:
            allowUnsupported: false
            image: quay.io/ceph/ceph:v18.2.2

          removeOSDsIfOutAndSafeToRemove: true
          mon:
            count: 5
          mgr:
            count: 2
            modules:
              - name: pg_autoscaler
                enabled: true
              - name: rook
                enabled: true
              - name: restful
                enabled: true
              - name: nfs
                enabled: false
              - name: cephadm
                enabled: false
              - name: diskprediction_local
                enabled: true
              - name: insights
                enabled: true

          dashboard:
            enabled: true
            ssl: false
            prometheusEndpoint: http://prometheus-kube-prometheus-prometheus.prometheus:9090
            prometheusEndpointSSLVerify: false

          network:
            provider: host

          storage:
            useAllNodes: false
            useAllDevices: false
            nodes:
              # extra 500GB
              - name: node60
                devices:
                  - name: /dev/disk/by-id/nvme-Samsung_SSD_970_EVO_500GB_S5H7NS0N812724P
              - name: node61
                devices:
                  - name: /dev/disk/by-id/nvme-TS2TMTE220S_I039920228
              - name: node62
                devices:
                  - name: /dev/disk/by-id/nvme-TS2TMTE220S_I039920226
              # extra 500G
              - name: node63
                devices:
                  - name: /dev/disk/by-id/nvme-TS500GMTE240S_H553520052
 
 
              # stuk:
              # - name: node64
              #   devices:
              #     - name: /dev/disk/by-id/nvme-TS4TMTE250S_I262140239
              - name: node65
                devices:
                  - name: /dev/disk/by-id/nvme-TS4TMTE250S_I262140226

          crashCollector:
            disable: true
            daysToRetain: 7

          placement:
            all:
              tolerations:
                - key: "node.kubernetes.io/unschedulable"
                  operator: "Exists"
                  effect: "NoSchedule"
                - key: node-role.kubernetes.io/control-plane
                  operator: "Exists"
                  effect: "NoSchedule"

        cephFileSystems: []
        cephBlockPoolsVolumeSnapshotClass:
          enabled: false
        cephFileSystemVolumeSnapshotClass:
          enabled: false
        cephBlockPools:
          - name: ceph-blockpool-big
            spec:
              replicated:
                size: 3
              enableRBDStats: false
            storageClass:
              enabled: false
          - name: ceph-blockpool-twice-replicated
            spec:
              replicated:
                size: 2
              enableRBDStats: false
            storageClass:
              enabled: false
        cephObjectStores: []
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
